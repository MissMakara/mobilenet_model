# -*- coding: utf-8 -*-
"""mobilenet_model_transform_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CKpBKdOkwDGKrCRazvHIlxzVl_5zl9gn
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.model_selection import train_test_split
import numpy as np 
from  matplotlib import pyplot as plt
import matplotlib.image as mpimg
# get_ipython().run_line_magic('matplotlib', 'inline')
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import joblib
from tensorflow import keras
from skimage.io import imread
from skimage.transform import resize
from sklearn import svm
import imutils
from imutils import paths
import tensorflow as tf
import os 
import cv2
import os

os.environ["CUDA_VISIBLE_DEVICES"] = "1"

# strategy = tf.distribute.MirroredStrategy()

# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
# tf.test.is_gpu_available()
# tf.config.list_physical_devices

def image_dataset(eye_dataset):
    
    IMG_WIDTH=224
    IMG_HEIGHT=224
    img_data_array=[]
    class_name=[]
    nd_image_array=[]
   
    for folder in os.listdir(eye_dataset):
        for file in os.listdir(os.path.join(eye_dataset,folder)):

          image_path= os.path.join(eye_dataset,folder,file)
          #image=mpimg.imread(image_path)
          image= cv2.imread(image_path,cv2.IMREAD_COLOR)

          #change image to np array and print shape
          image = np.array(image)
          
          
          #assign the dimensions
          try:
            ht =image.shape[0]
            wd =image.shape[1]
            cc =image.shape[2] 
            #print(image.shape)

          # create new image of desired size and color (blue) for padding
          #  ww = 300
          #  hh = 300
          #  color = (255,0,0)
          #  result = np.full((hh,ww,cc), color, dtype=np.uint8)

          #  xx = (ww - wd) // 2
         #   yy = (hh - ht) // 2


            # copy img image into center of result image
           # image = result[yy:yy+ht, xx:xx+wd]
          
            top_pad = np.floor((ht - image.shape[0]) / 2).astype(np.uint16)
            bottom_pad = np.ceil((ht - image.shape[0]) / 2).astype(np.uint16)
            right_pad = np.ceil((wd - image.shape[1]) / 2).astype(np.uint16)
            left_pad = np.floor((wd - image.shape[1]) / 2).astype(np.uint16)
            image = np.copy(np.pad(image, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)), mode='constant', constant_values=0))

            ht =0
            wd =0
            cc =0

            try:
                image =cv2.resize(image,(IMG_HEIGHT, IMG_WIDTH))
            except Exception as e:
                print(str(e))

            image=np.array(image)
            flat_image= image.flatten()
            image = image.astype('float32')
            #image /= 255 
            
            
            class_name.append(folder)
            img_data_array.append(flat_image)
            nd_image_array.append(image)
            
          except Exception as e:
            print(str(e))
            ax=plt.subplot(1,5,i+1)
            ax.title.set_text(file)
            plt.imshow(image)

    #img_data_array = np.array(img_data_array)
    #class_name = np.array(class_name)
    return img_data_array, class_name, nd_image_array



#from google.colab import drive
#drive.mount('/content/drive')


img_data_, class_names_, nd_array = image_dataset(r'../Eye colouration improvement/Edited Dataset 2')

nd_array = np.array(nd_array)

#img_data = np.array(img_data_)
class_names = np.array(class_names_)

class_names

X_ = nd_array
y_ = class_names

y_

y_array =np.array(y_)

X_.shape

from sklearn.utils import shuffle
X_,y_ = shuffle(X_, y_, random_state=32)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
target = le.fit_transform(y_)
target


#from keras.utils import np_utils
#y_cat = np_utils.to_categorical(target, 1000)



y_cat_ = tf.keras.utils.to_categorical(target, num_classes=1000)
print(y_cat_.shape)

X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_cat_, test_size=0.30, random_state=30)

X_train_.shape

from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True,
                                   rotation_range=40, 
                                   width_shift_range=0.2, 
                                   height_shift_range=0.2,
                                   fill_mode='nearest'
                                   )

#train_datagen.fit(X_train_)

mobilenet = keras.applications.MobileNet(
    alpha=1.0,
    depth_multiplier=1,
    dropout=0.001,
    include_top=True,
    classes=1000,
    classifier_activation="softmax"
)

mobilenet.compile(loss='CategoricalCrossentropy',
              optimizer= keras.optimizers.SGD(learning_rate=0.01),
              metrics=['CategoricalAccuracy'])

mobilenet.summary()

mobilenet.fit(train_datagen.flow(X_train_, y_train_, batch_size = 18),validation_data=(X_test_, y_test_), 
               epochs = 15)



mobilenet.save('mobilenet_model_2')
#mobilenet.fit(X_train_, y_train_, batch_size=64, epochs=1, validation_data=(X_test_, y_test_))